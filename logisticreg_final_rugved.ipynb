{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "37731006-de9e-44d6-8334-ba1901ecc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"D:\\prisha_manipal_sp\\sp_rugved\\heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2de18198-47fb-4095-a3bb-bb67cb0d0f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n",
      "3   0     2       1  \n",
      "4   0     2       1  \n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal          int64\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "114e0a0d-8823-4312-9f44-a04e8f7e1712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf3f3467-3868-4d1d-893f-6c0556079f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Calculate correlations\\ncorr_matrix = data.corr()\\n\\n# Visualize correlations\\nplt.figure(figsize=(10, 8))\\nsns.heatmap(corr_matrix, annot=True, cmap=\\'coolwarm\\', fmt=\\'.2f\\')\\nplt.title(\"Feature Correlation Heatmap\")\\nplt.show()'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "795afa7d-a528-4506-81ac-262c57607812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=['trestbps', 'chol', 'fbs', 'restecg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f46ab5a-fb7e-4952-b29e-656ea6540498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.drop(columns=['target'])  \n",
    "y = data['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2ca72b98-acfe-4914-bee3-c85b5c4d7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))                                                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed5b2ac5-b7f0-4d2c-9d28-0b93cbc64986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_features):\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cb7bd0f2-dace-435b-8f8c-33c942f973b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, weights, bias, threshold=0.5):\n",
    "    linear_output = np.dot(X, weights) + bias\n",
    "    \n",
    "    y_pred_prob = sigmoid(linear_output)\n",
    "    \n",
    "    y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f79d45d-bcff-404f-a663-4ff72371083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, learning_rate=0.01, epochs=500, l2_lambda=0.01):\n",
    "    n_features = X.shape[1]\n",
    "    weights, bias = initialize_parameters(n_features)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        linear_output = np.dot(X, weights) + bias\n",
    "        y_pred = sigmoid(linear_output)\n",
    "        loss = compute_loss(y, y_pred, weights, l2_lambda)\n",
    "        dw, db = gradients(X, y, y_pred, weights, l2_lambda)\n",
    "        weights, bias = update_parameters(weights, bias, dw, db, learning_rate)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d89a944f-bdcc-4090-b38c-8ef787eaa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y_true, y_pred, weights, l2_lambda):\n",
    "    n = X.shape[0]\n",
    "    dw = (1 / n) * np.dot(X.T, (y_pred - y_true)) + (l2_lambda / n) * weights \n",
    "    db = (1 / n) * np.sum(y_pred - y_true)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d583c6b7-9645-422a-ac5b-6bb616b7c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(weights, bias, dw, db, learning_rate):\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65b32410-a89a-43ee-8766-9bc12fc6241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, learning_rate=0.01, epochs=500, l2_lambda=0.01):\n",
    "    n_features = X.shape[1]\n",
    "    weights, bias = initialize_parameters(n_features)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        linear_output = np.dot(X, weights) + bias\n",
    "        y_pred = sigmoid(linear_output)   \n",
    "\n",
    "        #l2 regularization term\n",
    "        loss = compute_loss(y, y_pred, weights, l2_lambda)\n",
    "        dw, db = gradients(X, y, y_pred, weights, l2_lambda)\n",
    "        weights, bias = update_parameters(weights, bias, dw, db, learning_rate)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ae40e320-1425-4bc1-b375-38aca8c24997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599453\n",
      "Epoch 100, Loss: 0.6635717335508335\n",
      "Epoch 200, Loss: 0.6375947605773519\n",
      "Epoch 300, Loss: 0.6147425581769236\n",
      "Epoch 400, Loss: 0.5945940757281274\n",
      "Model Accuracy: 0.8283828382838284\n"
     ]
    }
   ],
   "source": [
    "weights, bias = train_logistic_regression(X_scaled, y, learning_rate=0.001, epochs=500, l2_lambda=0.01)\n",
    "\n",
    "# predict\n",
    "y_pred = forward(X_scaled, weights, bias)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"model accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b5b8cc76-f606-4187-8b2e-d2e44a298668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in target variable: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in target variable:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d6973-88fe-4bf8-8483-c4019a438af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
